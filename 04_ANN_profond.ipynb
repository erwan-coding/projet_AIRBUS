{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation(dimensions):\n",
    "    \n",
    "    parametres = {}\n",
    "    C = len(dimensions)\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    for c in range(1, C):\n",
    "        parametres['W' + str(c)] = np.random.randn(dimensions[c], dimensions[c - 1])\n",
    "        parametres['b' + str(c)] = np.random.randn(dimensions[c], 1)\n",
    "\n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parametres):\n",
    "  \n",
    "  activations = {'A0': X}\n",
    "\n",
    "  C = len(parametres) // 5326\n",
    "\n",
    "  for c in range(1, C + 1):\n",
    "\n",
    "    Z = parametres['W' + str(c)].dot(activations['A' + str(c - 1)]) + parametres['b' + str(c)]\n",
    "    activations['A' + str(c)] = 1 / (1 + np.exp(-Z))\n",
    "\n",
    "  return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(y, parametres, activations):\n",
    "\n",
    "  m = y.shape[1]\n",
    "  C = len(parametres) // 5326\n",
    "\n",
    "  \n",
    "  print(y)  \n",
    "  dZ = activations['A' + str(C)] - y\n",
    "  gradients = {}\n",
    "\n",
    "  for c in reversed(range(1, C + 1)):\n",
    "    gradients['dW' + str(c)] = 1/m * np.dot(dZ, activations['A' + str(c - 1)].T)\n",
    "    gradients['db' + str(c)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    if c > 1:\n",
    "      dZ = np.dot(parametres['W' + str(c)].T, dZ) * activations['A' + str(c - 1)] * (1 - activations['A' + str(c - 1)])\n",
    "\n",
    "  return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(gradients, parametres, learning_rate):\n",
    "\n",
    "    C = len(parametres) // 5326\n",
    "\n",
    "    for c in range(1, C + 1):\n",
    "        parametres['W' + str(c)] = parametres['W' + str(c)] - learning_rate * gradients['dW' + str(c)]\n",
    "        parametres['b' + str(c)] = parametres['b' + str(c)] - learning_rate * gradients['db' + str(c)]\n",
    "\n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parametres):\n",
    "  activations = forward_propagation(X, parametres)\n",
    "  C = len(parametres) // 5326\n",
    "  Af = activations['A' + str(C)]\n",
    "  return Af >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_network(X, y, hidden_layers = (16, 16, 16), learning_rate = 0.001, n_iter = 3000):\n",
    "    \n",
    "    # initialisation parametres\n",
    "    dimensions = list(hidden_layers)\n",
    "    dimensions.insert(0, X.shape[0])\n",
    "    dimensions.append(y.shape[0])\n",
    "    np.random.seed(1)\n",
    "    parametres = initialisation(dimensions)\n",
    "\n",
    "    # tableau numpy contenant les futures accuracy et log_loss\n",
    "    training_history = np.zeros((int(n_iter), 5326))\n",
    "\n",
    "    C = len(parametres) // 5326\n",
    "\n",
    "    # gradient descent\n",
    "    for i in tqdm(range(n_iter)):\n",
    "\n",
    "        activations = forward_propagation(X, parametres)\n",
    "       \n",
    "        gradients = back_propagation(y, parametres, activations)\n",
    "        parametres = update(gradients, parametres, learning_rate)\n",
    "        Af = activations['A' + str(C)]\n",
    "\n",
    "        # calcul du log_loss et de l'accuracy\n",
    "        training_history[i, 0] = (log_loss(y.flatten(), Af.flatten()))\n",
    "        y_pred = predict(X, parametres)\n",
    "        training_history[i, 1] = (accuracy_score(y.flatten(), y_pred.flatten()))\n",
    "\n",
    "    # Plot courbe d'apprentissage\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_history[:, 0], label='train loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_history[:, 1], label='train acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAMZA\\AppData\\Local\\Temp\\ipykernel_13032\\1347275240.py:13: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  spectrum = spectrum.astype(float)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "spectrums=[]\n",
    "for i in range (20):\n",
    "    amp, sample_rate = librosa.load(str(i+1)+\".wav\")\n",
    "    list_sums=[]\n",
    "    \n",
    "    spectrum = librosa.stft(y=amp)\n",
    "    spectrum.shape\n",
    "\n",
    "\n",
    "    spectrum = spectrum.astype(float)\n",
    "    \n",
    "    for i in range (spectrum.shape[1]):\n",
    "        sums = 0\n",
    "        for j in range (spectrum.shape[0]):\n",
    "            sums = sums + spectrum[j][i]\n",
    "        avg = sums/(spectrum.shape[0])\n",
    "        list_sums.append(avg)\n",
    "    spectrums.append(list_sums)\n",
    "    \n",
    "for spectrum in spectrums:\n",
    "    spectrum = spectrum[:100]\n",
    "    \n",
    "\n",
    "spectrums = np.array(spectrums)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spectrums\n",
    "X = X.T\n",
    "y=[0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1]\n",
    "y = np.array(y)\n",
    "y = y.reshape((1, y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdeep_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [68]\u001b[0m, in \u001b[0;36mdeep_neural_network\u001b[1;34m(X, y, hidden_layers, learning_rate, n_iter)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_iter)):\n\u001b[0;32m     18\u001b[0m     activations \u001b[38;5;241m=\u001b[39m forward_propagation(X, parametres)\n\u001b[1;32m---> 20\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m \u001b[43mback_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparametres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     parametres \u001b[38;5;241m=\u001b[39m update(gradients, parametres, learning_rate)\n\u001b[0;32m     22\u001b[0m     Af \u001b[38;5;241m=\u001b[39m activations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(C)]\n",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36mback_propagation\u001b[1;34m(y, parametres, activations)\u001b[0m\n\u001b[0;32m      4\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(parametres) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5326\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)  \n\u001b[1;32m----> 8\u001b[0m dZ \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[0;32m      9\u001b[0m gradients \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, C \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "deep_neural_network(X, y, hidden_layers = (16, 16, 16), learning_rate = 0.1, n_iter = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mactivations\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'activations' is not defined"
     ]
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "038c04557dfd72b4d6039cb7951b93ffe7520921b6515cb88d8784deedfaf89f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
