{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_to_db_voice = \"D:\\\\Utilisateurs\\\\ENAC\\\\projet_AIRBUS\\\\db\\\\voice\\\\\"\n",
    "path_to_db_plane = \"D:\\\\Utilisateurs\\\\ENAC\\\\projet_AIRBUS\\\\db\\\\plane\\\\\"\n",
    "path_to_db_both = \"D:\\\\Utilisateurs\\\\ENAC\\\\projet_AIRBUS\\\\db\\\\both\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = joblib.load(\"random_forest2.joblib\")\n",
    "conv = load_model('Conv2D.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_valid_test(db_folder_path,n_records):\n",
    "\n",
    "    l_records = os.listdir(db_folder_path)\n",
    "    sub_l_records = rd.sample(l_records,n_records)\n",
    "    sample = rd.sample(sub_l_records,n_records)\n",
    "    sp_valid_rf = []\n",
    "    sp_valid_conv = []\n",
    "    hops_valid = []\n",
    "    for i in range(n_records):\n",
    "        print('Building validation set {}/{}'.format(i,n_records),end='\\r')\n",
    "        signal,sample_rate = librosa.load(db_folder_path + sample[i])\n",
    "        spectrum = librosa.stft(y=signal,center=False) \n",
    "        spectrum = spectrum.astype(float)\n",
    "        # fig, ax = plt.subplots()\n",
    "        # img = librosa.display.specshow(librosa.amplitude_to_db(spectrum),y_axis='log', x_axis='time', ax=ax)\n",
    "        # ax.set_title('Power spectrogram')\n",
    "        # fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "        # plt.show()\n",
    "\n",
    "        #pour le réseau convolutif\n",
    "        conv_spectrum = spectrum[:,:100]\n",
    "        if conv_spectrum.shape == (1025,100):\n",
    "            sp_valid_conv.append(librosa.amplitude_to_db(conv_spectrum))\n",
    "\n",
    "            #pour la random forest \n",
    "            rf_spectrum = np.abs(np.transpose(spectrum))\n",
    "            sp_valid_rf.append(rf_spectrum)\n",
    "            hops_valid.append(len(signal)//len(rf_spectrum))\n",
    "\n",
    "    return sp_valid_rf,hops_valid,np.array(sp_valid_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_voice2(x,hop,duration_sec_threshold,error_threshold):\n",
    "    ratio = np.count_nonzero(x=='Voice')/len(x)\n",
    "    duration_discrete_threshold = round(duration_sec_threshold * 22050 / hop)\n",
    "    binary_pred = [0 if elt=='Plane' else 1 for elt in x]\n",
    "    df_x = pd.DataFrame(binary_pred)\n",
    "    df_sum = df_x.rolling(duration_discrete_threshold).mean()\n",
    "    x_plot = [elt*hop/22050 for elt in range(len(x))] #x en seconds\n",
    "    # plt.plot(x_plot,df_sum[0])\n",
    "    # plt.show()\n",
    "    return len(df_sum[df_sum[0]>error_threshold])>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building validation set 49/50\r"
     ]
    }
   ],
   "source": [
    "rf_plane_valid,hops_plane_valid,conv_plane_valid = gen_valid_test(path_to_db_plane,50)\n",
    "rf_both_valid,hops_both_valid,conv_both_valid = gen_valid_test(path_to_db_both,50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARTIE RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plane_y = np.array([0 for i in range(len(rf_plane_valid))])\n",
    "rf_both_y = np.array([1 for i in range(len(rf_both_valid))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6530612244897959, 0.9795918367346939)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_for_records_plane = []\n",
    "for i  in range(len(rf_plane_valid)):\n",
    "    pred = rf.predict(rf_plane_valid[i])\n",
    "    prediction_for_records_plane.append(has_voice2(pred,hops_plane_valid[i],1,0.8))\n",
    "\n",
    "prediction_for_records_both = []\n",
    "for i  in range(len(rf_plane_valid)):\n",
    "    pred = rf.predict(rf_both_valid[i])\n",
    "    prediction_for_records_both.append(has_voice2(pred,hops_both_valid[i],1,0.8))\n",
    "\n",
    "\n",
    "accuracy_score(rf_plane_y,prediction_for_records_plane),accuracy_score(rf_both_y,prediction_for_records_both)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARTIE RESEAU CONVOLUTIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_plane_y = np.array([0 for i in range(len(conv_plane_valid))])\n",
    "conv_both_y = np.array([1 for i in range(len(conv_both_valid))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8163265306122449, 0.8979591836734694)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_for_records_plane = conv(conv_plane_valid).numpy().astype(int)\n",
    "prediction_for_records_both = conv(conv_both_valid).numpy().astype(int)\n",
    "# prediction_for_records_plane\n",
    "accuracy_score(conv_plane_y,prediction_for_records_plane),accuracy_score(conv_both_y,prediction_for_records_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_of_models_valid(rf,conv):\n",
    "\n",
    "    rf_plane_valid,hops_plane_valid,conv_plane_valid = gen_valid_test(path_to_db_plane,60)\n",
    "    rf_both_valid,hops_both_valid,conv_both_valid = gen_valid_test(path_to_db_both,60)\n",
    "    y_plane = np.array([0 for i in range(len(rf_plane_valid))])\n",
    "    y_both = np.array([1 for i in range(len(rf_both_valid))])\n",
    "\n",
    "    rf_valid = np.concatenate([rf_plane_valid,rf_both_valid])\n",
    "    hops_valid = np.concatenate([hops_plane_valid,hops_both_valid])\n",
    "    conv_valid = np.concatenate([conv_plane_valid,conv_both_valid])\n",
    "\n",
    "    n = len(rf_valid)\n",
    "    print(len(rf_valid),len(conv_both_valid)+len(conv_plane_valid))\n",
    "    y_valid = np.concatenate([y_plane,y_both])\n",
    "\n",
    "    rf_prediction = []\n",
    "    for i  in range(n):\n",
    "        pred = rf.predict(rf_valid[i])\n",
    "        rf_prediction.append(has_voice2(pred,hops_valid[i],1,0.8))\n",
    "\n",
    "    conv_prediction = conv(conv_valid).numpy().astype(int)\n",
    "\n",
    "    final_pred = []\n",
    "    for i in range(n):\n",
    "        if rf_prediction[i]==1 and conv_prediction[i]==0: \n",
    "            final_pred.append(0)\n",
    "        elif rf_prediction[i]==1 and conv_prediction[i]==1:\n",
    "            final_pred.append(1)\n",
    "        elif rf_prediction[i]==0 and conv_prediction[i]==0:\n",
    "            final_pred.append(0)\n",
    "        else :\n",
    "            final_pred.append(1) #c'est nul\n",
    "\n",
    "    return final_pred,y_valid,rf_prediction,conv_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 119g validation set 59/60\n"
     ]
    }
   ],
   "source": [
    "final_pred,y_valid,rf_prediction,conv_prediction = mix_of_models_valid(rf,conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les deux modèles combinés: 0.8739495798319328\n",
      "Random Forest seule: 0.7899159663865546\n",
      "Conv2D seul: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "print(\"Les deux modèles combinés:\",accuracy_score(y_valid,final_pred))\n",
    "print(\"Random Forest seule:\",accuracy_score(y_valid,rf_prediction))\n",
    "print(\"Conv2D seul:\",accuracy_score(y_valid,conv_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57fc1ca9e7a3b36fb7482b4c918a6cca87efa7be43ecf423d462955f51660388"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
