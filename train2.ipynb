{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129f3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TimeDistributed, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import kapre\n",
    "from kapre.composed import get_melspectrogram_layer\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b108bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import argparse\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8629d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={'src_root':'cleanwavs',\n",
    "      'batch_size':16,\n",
    "     'delta_time':1.0,\n",
    "     'model_type':'conv2d',\n",
    "     'sample_rate':16000,\n",
    "      'fn':'3a3d0279'\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd17d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D(N_LABELS=2, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                 n_mels=128,\n",
    "                                 pad_end=True,\n",
    "                                 n_fft=512,\n",
    "                                 win_length=400,\n",
    "                                 hop_length=160,\n",
    "                                 sample_rate=SR,\n",
    "                                 return_decibel=True,\n",
    "                                 input_data_format='channels_last',\n",
    "                                 output_data_format='channels_last')\n",
    "    n = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    n = layers.Conv2D(8, kernel_size=(7, 7), activation='tanh',\n",
    "                      padding='same', name='conv2d_tanh')(n)\n",
    "    n = layers.MaxPooling2D(pool_size=(\n",
    "        2, 2), padding='same', name='max_pool_2d_1')(n)\n",
    "    n = layers.Conv2D(16, kernel_size=(5, 5), activation='relu',\n",
    "                      padding='same', name='conv2d_relu_1')(n)\n",
    "    n = layers.MaxPooling2D(pool_size=(\n",
    "        2, 2), padding='same', name='max_pool_2d_2')(n)\n",
    "    n = layers.Conv2D(16, kernel_size=(3, 3), activation='relu',\n",
    "                      padding='same', name='conv2d_relu_2')(n)\n",
    "    n = layers.MaxPooling2D(pool_size=(\n",
    "        2, 2), padding='same', name='max_pool_2d_3')(n)\n",
    "    n = layers.Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                      padding='same', name='conv2d_relu_3')(n)\n",
    "    n = layers.MaxPooling2D(pool_size=(\n",
    "        2, 2), padding='same', name='max_pool_2d_4')(n)\n",
    "    n = layers.Conv2D(32, kernel_size=(3, 3), activation='relu',\n",
    "                      padding='same', name='conv2d_relu_4')(n)\n",
    "    n = layers.Flatten(name='flatten')(n)\n",
    "    n = layers.Dropout(rate=0.2, name='dropout')(n)\n",
    "    n = layers.Dense(64, activation='relu',\n",
    "                     activity_regularizer=l2(0.001), name='dense')(n)\n",
    "    o = layers.Dense(N_LABELS, activation='softmax', name='softmax')(n)\n",
    "    model = Model(inputs=i.input, outputs=o, name='2d_convolution')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00b9746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(N_LABELS=2, SR=16000, DT=1.0):\n",
    "    input_shape = (int(SR*DT), 1)\n",
    "    i = get_melspectrogram_layer(input_shape=input_shape,\n",
    "                                 n_mels=128,\n",
    "                                 pad_end=True,\n",
    "                                 n_fft=512,\n",
    "                                 win_length=400,\n",
    "                                 hop_length=160,\n",
    "                                 sample_rate=SR,\n",
    "                                 return_decibel=True,\n",
    "                                 input_data_format='channels_last',\n",
    "                                 output_data_format='channels_last',\n",
    "                                 name='2d_convolution')\n",
    "    n = LayerNormalization(axis=2, name='batch_norm')(i.output)\n",
    "    n = TimeDistributed(layers.Reshape((-1,)), name='reshape')(n)\n",
    "    k = TimeDistributed(layers.Dense(64, activation='tanh'),\n",
    "                        name='td_dense_tanh')(n)\n",
    "    n = layers.Bidirectional(layers.LSTM(32, return_sequences=True),\n",
    "                             name='bidirectional_lstm')(k)\n",
    "    n = layers.concatenate([k, n], axis=2, name='skip_connection')\n",
    "    n = layers.Dense(64, activation='relu', name='dense_1_relu')(n)\n",
    "    n = layers.MaxPooling1D(name='max_pool_1d')(n)\n",
    "    n = layers.Dense(32, activation='relu', name='dense_2_relu')(n)\n",
    "    n = layers.Flatten(name='flatten')(n)\n",
    "    n = layers.Dropout(rate=0.2, name='dropout')(n)\n",
    "    n = layers.Dense(32, activation='relu',\n",
    "                     activity_regularizer=l2(0.001),\n",
    "                     name='dense_3_relu')(n)\n",
    "    o = layers.Dense(N_LABELS, activation='softmax', name='softmax')(n)\n",
    "    print(i.input)\n",
    "    model = Model(inputs=i.input, outputs=o, name='long_short_term_memory')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35498788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9f208ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import argparse\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64b88695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, wav_paths, labels, sr, dt,n_labels,\n",
    "                 batch_size=32, shuffle=True):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.dt = dt\n",
    "        self.n_labels = n_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = True\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # retourne le nbr de batch dans le dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.wav_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        # genere un batch de time data\n",
    "        X = np.empty((self.batch_size, int(self.sr*self.dt), 1),\n",
    "                     dtype=np.float32)\n",
    "        Y = np.empty((self.batch_size, self.n_labels), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n",
    "            rate, wav = wavfile.read(path)\n",
    "            X[i,] = X[i,][:16000]\n",
    "            # X[i,] = wav.reshape(-1, 1)\n",
    "            for j in range(len(X[i,])):\n",
    "                X[i,][j] = wav.reshape(-1, 1)[j]\n",
    "            Y[i,] = to_categorical(label, num_classes=self.n_labels)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    # mélange les chemins et les étiquettes des fichiers audio à la fin de chaque époque si shufflec'est True.\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2074d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    src_root = args['src_root']\n",
    "    sr = args['sample_rate']\n",
    "    dt = args['delta_time']\n",
    "    batch_size = args['batch_size']\n",
    "    model_type = args['model_type']\n",
    "    params = {'N_LABELS': len(os.listdir(args['src_root'])),\n",
    "              'SR': sr,\n",
    "              'DT': dt}\n",
    "    models = {'conv2d': Conv2D(**params),\n",
    "              'lstm':  LSTM(**params)}\n",
    "    assert model_type in models.keys(), '{} is unavailable'.format(model_type)\n",
    "    csv_path = os.path.join('logs', '{}_history.csv'.format(model_type))\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n",
    "    wav_paths = [n.replace(os.sep, '/') for n in wav_paths if '.wav' in n]\n",
    "    classes = sorted(os.listdir(args['src_root']))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(n)[0].split('/')[-1] for n in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.1,\n",
    "                                                                  random_state=10)\n",
    "\n",
    "    assert len(label_train) >= args['batch_size'], 'Nbr of train samples should be higher than the batch_size'\n",
    "    if len(set(label_train)) != params['N_LABELS']:\n",
    "        warnings.warn('Found {}/{} labels in training data. Increase the size or change random_state.'.format(\n",
    "            len(set(label_train)), params['N_LABELS']))\n",
    "    if len(set(label_val)) != params['N_LABELS']:\n",
    "        warnings.warn('Found {}/{} labels in validation data. Increase the size or change random_state.'.format(\n",
    "            len(set(label_val)), params['N_LABELS']))\n",
    "\n",
    "    tg = DataGenerator(wav_train, label_train, sr, dt,\n",
    "                       params['N_LABELS'], batch_size=batch_size)\n",
    "    vg = DataGenerator(wav_val, label_val, sr, dt,\n",
    "                       params['N_LABELS'], batch_size=batch_size)\n",
    "    model = models[model_type]\n",
    "    cp = ModelCheckpoint('vers_fin/{}.h5'.format(model_type), monitor='val_loss',\n",
    "                         save_best_only=True, save_weights_only=False,\n",
    "                         mode='auto', save_freq='epoch', verbose=1)\n",
    "    csv_logger = CSVLogger(csv_path, append=False)\n",
    "    model.fit(tg, validation_data=vg,\n",
    "              epochs=30, verbose=1,\n",
    "              callbacks=[csv_logger, cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fae44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeaf9348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"stft_5_input:0\", shape=(None, 16000, 1), dtype=float32)\n",
      "Epoch 1/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.8261\n",
      "Epoch 00001: val_loss improved from inf to 0.16463, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 20s 283ms/step - loss: 0.3764 - accuracy: 0.8261 - val_loss: 0.1646 - val_accuracy: 0.9375\n",
      "Epoch 2/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9212\n",
      "Epoch 00002: val_loss improved from 0.16463 to 0.09015, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 270ms/step - loss: 0.2151 - accuracy: 0.9212 - val_loss: 0.0901 - val_accuracy: 0.9821\n",
      "Epoch 3/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.9248\n",
      "Epoch 00003: val_loss improved from 0.09015 to 0.08445, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.2047 - accuracy: 0.9248 - val_loss: 0.0844 - val_accuracy: 0.9911\n",
      "Epoch 4/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9475\n",
      "Epoch 00004: val_loss did not improve from 0.08445\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.2015 - accuracy: 0.9475 - val_loss: 0.1481 - val_accuracy: 0.9643\n",
      "Epoch 5/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.9719\n",
      "Epoch 00005: val_loss improved from 0.08445 to 0.05930, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.1322 - accuracy: 0.9719 - val_loss: 0.0593 - val_accuracy: 0.9821\n",
      "Epoch 6/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9638\n",
      "Epoch 00006: val_loss did not improve from 0.05930\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.1233 - accuracy: 0.9638 - val_loss: 0.1714 - val_accuracy: 0.9286\n",
      "Epoch 7/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9665\n",
      "Epoch 00007: val_loss did not improve from 0.05930\n",
      "69/69 [==============================] - 19s 270ms/step - loss: 0.1231 - accuracy: 0.9665 - val_loss: 0.1024 - val_accuracy: 0.9554\n",
      "Epoch 8/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9783\n",
      "Epoch 00008: val_loss did not improve from 0.05930\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0948 - accuracy: 0.9783 - val_loss: 0.0665 - val_accuracy: 0.9821\n",
      "Epoch 9/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9801\n",
      "Epoch 00009: val_loss improved from 0.05930 to 0.03655, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.0785 - accuracy: 0.9801 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9864\n",
      "Epoch 00010: val_loss improved from 0.03655 to 0.02623, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0603 - accuracy: 0.9864 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9837\n",
      "Epoch 00011: val_loss improved from 0.02623 to 0.02447, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0652 - accuracy: 0.9837 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9402\n",
      "Epoch 00012: val_loss did not improve from 0.02447\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.1453 - accuracy: 0.9402 - val_loss: 0.1622 - val_accuracy: 0.9554\n",
      "Epoch 13/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9592\n",
      "Epoch 00013: val_loss did not improve from 0.02447\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.1145 - accuracy: 0.9592 - val_loss: 0.2650 - val_accuracy: 0.9107\n",
      "Epoch 14/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.9710\n",
      "Epoch 00014: val_loss did not improve from 0.02447\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0979 - accuracy: 0.9710 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9882\n",
      "Epoch 00015: val_loss did not improve from 0.02447\n",
      "69/69 [==============================] - 19s 274ms/step - loss: 0.0507 - accuracy: 0.9882 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9873\n",
      "Epoch 00016: val_loss did not improve from 0.02447\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.0548 - accuracy: 0.9873 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9982\n",
      "Epoch 00017: val_loss improved from 0.02447 to 0.01839, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 273ms/step - loss: 0.0256 - accuracy: 0.9982 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9891\n",
      "Epoch 00018: val_loss did not improve from 0.01839\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.0429 - accuracy: 0.9891 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.9873\n",
      "Epoch 00019: val_loss did not improve from 0.01839\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0491 - accuracy: 0.9873 - val_loss: 0.0585 - val_accuracy: 0.9821\n",
      "Epoch 20/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9946\n",
      "Epoch 00020: val_loss did not improve from 0.01839\n",
      "69/69 [==============================] - 19s 273ms/step - loss: 0.0425 - accuracy: 0.9946 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9891\n",
      "Epoch 00021: val_loss did not improve from 0.01839\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9973\n",
      "Epoch 00022: val_loss did not improve from 0.01839\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.0273 - accuracy: 0.9973 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9973\n",
      "Epoch 00023: val_loss improved from 0.01839 to 0.01838, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.0214 - accuracy: 0.9973 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9991\n",
      "Epoch 00024: val_loss improved from 0.01838 to 0.01681, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 275ms/step - loss: 0.0184 - accuracy: 0.9991 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9991\n",
      "Epoch 00025: val_loss did not improve from 0.01681\n",
      "69/69 [==============================] - 19s 272ms/step - loss: 0.0196 - accuracy: 0.9991 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9991\n",
      "Epoch 00026: val_loss did not improve from 0.01681\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0168 - accuracy: 0.9991 - val_loss: 0.0246 - val_accuracy: 0.9911\n",
      "Epoch 27/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9991\n",
      "Epoch 00027: val_loss improved from 0.01681 to 0.01575, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 270ms/step - loss: 0.0150 - accuracy: 0.9991 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9982\n",
      "Epoch 00028: val_loss did not improve from 0.01575\n",
      "69/69 [==============================] - 19s 271ms/step - loss: 0.0215 - accuracy: 0.9982 - val_loss: 0.0212 - val_accuracy: 0.9911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 00029: val_loss improved from 0.01575 to 0.01381, saving model to vers_fin\\lstm.h5\n",
      "69/69 [==============================] - 19s 270ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9982\n",
      "Epoch 00030: val_loss did not improve from 0.01381\n",
      "69/69 [==============================] - 19s 277ms/step - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.0759 - val_accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec57ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"stft_7_input:0\", shape=(None, 16000, 1), dtype=float32)\n",
      "Epoch 1/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.8089\n",
      "Epoch 00001: val_loss improved from inf to 0.24530, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 308ms/step - loss: 0.3744 - accuracy: 0.8089 - val_loss: 0.2453 - val_accuracy: 0.8750\n",
      "Epoch 2/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.9493\n",
      "Epoch 00002: val_loss improved from 0.24530 to 0.06703, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 304ms/step - loss: 0.1638 - accuracy: 0.9493 - val_loss: 0.0670 - val_accuracy: 0.9911\n",
      "Epoch 3/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9692\n",
      "Epoch 00003: val_loss improved from 0.06703 to 0.06112, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 302ms/step - loss: 0.1166 - accuracy: 0.9692 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9728\n",
      "Epoch 00004: val_loss improved from 0.06112 to 0.04171, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 301ms/step - loss: 0.1119 - accuracy: 0.9728 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9764\n",
      "Epoch 00005: val_loss improved from 0.04171 to 0.03780, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 301ms/step - loss: 0.0867 - accuracy: 0.9764 - val_loss: 0.0378 - val_accuracy: 0.9911\n",
      "Epoch 6/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9864\n",
      "Epoch 00006: val_loss improved from 0.03780 to 0.03300, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 306ms/step - loss: 0.0702 - accuracy: 0.9864 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9873\n",
      "Epoch 00007: val_loss improved from 0.03300 to 0.02751, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 304ms/step - loss: 0.0710 - accuracy: 0.9873 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9837\n",
      "Epoch 00008: val_loss did not improve from 0.02751\n",
      "69/69 [==============================] - 21s 305ms/step - loss: 0.0632 - accuracy: 0.9837 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 0.9828\n",
      "Epoch 00009: val_loss improved from 0.02751 to 0.02266, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 311ms/step - loss: 0.0588 - accuracy: 0.9828 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9937\n",
      "Epoch 00010: val_loss improved from 0.02266 to 0.01849, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 307ms/step - loss: 0.0410 - accuracy: 0.9937 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9973\n",
      "Epoch 00011: val_loss did not improve from 0.01849\n",
      "69/69 [==============================] - 21s 302ms/step - loss: 0.0294 - accuracy: 0.9973 - val_loss: 0.0621 - val_accuracy: 0.9821\n",
      "Epoch 12/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9937\n",
      "Epoch 00012: val_loss improved from 0.01849 to 0.01657, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 302ms/step - loss: 0.0368 - accuracy: 0.9937 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9918\n",
      "Epoch 00013: val_loss did not improve from 0.01657\n",
      "69/69 [==============================] - 21s 304ms/step - loss: 0.0339 - accuracy: 0.9918 - val_loss: 0.0253 - val_accuracy: 0.9911\n",
      "Epoch 14/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9900\n",
      "Epoch 00014: val_loss improved from 0.01657 to 0.01646, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 304ms/step - loss: 0.0394 - accuracy: 0.9900 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9973\n",
      "Epoch 00015: val_loss improved from 0.01646 to 0.01434, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 304ms/step - loss: 0.0239 - accuracy: 0.9973 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 00016: val_loss did not improve from 0.01434\n",
      "69/69 [==============================] - 21s 306ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9982\n",
      "Epoch 00017: val_loss did not improve from 0.01434\n",
      "69/69 [==============================] - 21s 303ms/step - loss: 0.0172 - accuracy: 0.9982 - val_loss: 0.0431 - val_accuracy: 0.9821\n",
      "Epoch 18/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9891\n",
      "Epoch 00018: val_loss did not improve from 0.01434\n",
      "69/69 [==============================] - 21s 306ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 0.0275 - val_accuracy: 0.9911\n",
      "Epoch 19/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9900\n",
      "Epoch 00019: val_loss did not improve from 0.01434\n",
      "69/69 [==============================] - 21s 303ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9955\n",
      "Epoch 00020: val_loss improved from 0.01434 to 0.01127, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 305ms/step - loss: 0.0240 - accuracy: 0.9955 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9955\n",
      "Epoch 00021: val_loss did not improve from 0.01127\n",
      "69/69 [==============================] - 21s 303ms/step - loss: 0.0221 - accuracy: 0.9955 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9991\n",
      "Epoch 00022: val_loss did not improve from 0.01127\n",
      "69/69 [==============================] - 21s 307ms/step - loss: 0.0145 - accuracy: 0.9991 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9982\n",
      "Epoch 00023: val_loss improved from 0.01127 to 0.01124, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 304ms/step - loss: 0.0154 - accuracy: 0.9982 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9973\n",
      "Epoch 00024: val_loss improved from 0.01124 to 0.00913, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 303ms/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9982\n",
      "Epoch 00025: val_loss did not improve from 0.00913\n",
      "69/69 [==============================] - 21s 302ms/step - loss: 0.0134 - accuracy: 0.9982 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9973\n",
      "Epoch 00026: val_loss improved from 0.00913 to 0.00902, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 306ms/step - loss: 0.0175 - accuracy: 0.9973 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9982\n",
      "Epoch 00027: val_loss improved from 0.00902 to 0.00832, saving model to vers_fin\\conv2d.h5\n",
      "69/69 [==============================] - 21s 302ms/step - loss: 0.0121 - accuracy: 0.9982 - val_loss: 0.0083 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9964\n",
      "Epoch 00028: val_loss did not improve from 0.00832\n",
      "69/69 [==============================] - 21s 303ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9964\n",
      "Epoch 00029: val_loss did not improve from 0.00832\n",
      "69/69 [==============================] - 21s 302ms/step - loss: 0.0206 - accuracy: 0.9964 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "69/69 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9982\n",
      "Epoch 00030: val_loss did not improve from 0.00832\n",
      "69/69 [==============================] - 21s 304ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.0288 - val_accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010c6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aafb0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224baf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b803ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66908fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff30a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4df4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e94116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fe807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f1a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734ccd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
